import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain_community.chat_models import ChatOpenAI

OPENAI_API_KEY = "Enter Open AI Key" # Open AI Key

# Upload PDF Files
st.header ("My First Chatbot")

with st.sidebar:
    st.title ("Your Documents")
    file = st.file_uploader("Upload a PDF file and start asking questions", type="pdf")

# Extract The Text
if file is not None:
    pdf_reader = PdfReader(file)
    text=""
    for page in pdf_reader.pages:
        text+=page.extract_text()
        # st.write(text)


# Break It Into Chunks
    text_splitter = RecursiveCharacterTextSplitter(
        # separators="\n",
        chunk_size=1000,
        chunk_overlap=150,
        length_function=len
    )
    chucks = text_splitter.split_text(text)
    # st.write(chucks)

# Generate Embeddings
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

# Creating Vector Store - FAISS
    vector_store = FAISS.from_texts(chucks, embeddings)
# Steps of above code
# 1) Embeddings via OpenAI
# 2) Initizling FAISS Database
# 3) Store Chucks & Embeddings

# Get User Questions - Prompt Engineering
    user_questions = st.text_input("Type your question here")
# Similarity Search
    if user_questions:
        match = vector_store.similarity_search(user_questions)
        # st.write(match)

# Define the LLM
        llm = ChatOpenAI(
            openai_api_key = OPENAI_API_KEY,
            temperature = 0,
            # max_token = 1000,
            model_name = "gpt-3.5-turbo"
        )

# Output Results
# Chain -> take the question, get_relevant_documents, pass_it_to_the_LLC, generate_the_output
        chain = load_qa_chain(llm, chain_type="stuff")
        response = chain.run(input_documents = match, question = user_questions)
        st.write(response)
